import json
import logging
import os
from glob import glob
from uuid import uuid4
from typing import Any, Dict, TypeVar

from scripts.normalization import cpes_from_vendor_and_product, parse_cpe_5_version_info, normalize_collection_url, generate_candidates, normalize_vendor, normalize

MAX_BATCH_SIZE=25

nvd_override_base_path = "/Users/weston/github/anchore/nvd-data-overrides"
nvd_override_files = glob(os.path.join(nvd_override_base_path, "overrides/**/CVE-*.json"))
nvd_record_base_path = "/Users/weston/github/westonsteimel/national-vulnerability-database/data"
cve5_data_files = glob("/Users/weston/github/westonsteimel/cvelist-v5/cves/**/**/CVE-*.json")

only_allowed_assigners = True

allowed_assigners = {
    "adobe",
    "go",
    "curl",
    "cloudflare",
    "google",
    "chrome",
    "mozilla",
    "gitlab",
    "oracle",
    "redhat",
    "fedora",
    #"jenkins",
    "github_m",
    "github_p",
    "wpscan",
    #"rapid7",
    "postgresql",
    #"atlassian",
    "isc",
    "icscert",
    #"cisa-cg",
    "cisco",
    "grafana",
    "openvpn",
    "wolfssl",
    "nlnet labs",
    #"silabs",
    "psf",
    #"canonical",
    "jetbrains",
    "jfrog",
    #"siemens",
    "apache",
    "wordfence",
    "concretecms",
    "libreswan",
    "patchstack",
}

ignore_assigners = {
    "vuldb",
    "fluid attacks",
    "incibe",
    "google_devices",
    "sap",
    "liferay",
    "google_android",
}

ignore_cves = {
    "CVE-2023-3966",
    "CVE-2024-1062",
    "CVE-2024-1722", # no upstream version info provided by RedHat
    "CVE-2024-1485", # no upstream version info provided by RedHat
    "CVE-2024-1342", # no upstream version info provided by RedHat
    "CVE-2024-1454", # no upstream version info provided by RedHat
    "CVE-2024-1151", # Linux kernel
    "CVE-2023-6681", # no upstream version info provided by RedHat
    "CVE-2024-2045", # session android app
    "CVE-2023-6132", # aviva edge
    "CVE-2024-20325", # cisco 
    "CVE-2024-20294", # cisco possibly incorrect cve data
}

# filter out stuff we don't care about right now
ignore_cpes = {
    "cpe:2.3:a:freebsd:freebsd:*:*:*:*:*:*:*:*",
    "cpe:2.3:a:microsoft:defender_for_endpoint:*:*:*:*:*:*:*:*",
    "cpe:2.3:a:miraheze:managewiki:*:*:*:*:*:*:*:*", # only git repo commit info, no releases
    "cpe:2.3:a:cisco:unified_computing_system:*:*:*:*:*:*:*:*",
    "cpe:2.3:a:cisco:ucs_central_software:*:*:*:*:*:*:*:*",
    "cpe:2.3:a:cisco:ucs_manager:*:*:*:*:*:*:*:*",
}

ignore_vendors = {
    "netapp",
    "ibm",
}

KeyType = TypeVar('KeyType')

def deep_update(mapping: Dict[KeyType, Any], *updating_mappings: Dict[KeyType, Any]) -> Dict[KeyType, Any]:
    updated_mapping = mapping.copy()
    for updating_mapping in updating_mappings:
        for k, v in updating_mapping.items():
            if k in updated_mapping and isinstance(updated_mapping[k], dict) and isinstance(v, dict):
                updated_mapping[k] = deep_update(updated_mapping[k], v)
            else:
                updated_mapping[k] = v
    return updated_mapping

class CPEPatternLookup:
    def __init__(self, curated_files: list[str], generated_files: list[str], logger: logging.Logger=None):
        if not logger:
            logger = logging.getLogger(self.__class__.__name__)
        self.logger = logger
        self.cpe_types = ["application", "os", "hardware"]
        self.__lookup_by_collection_url_and_package_name__: dict[str, dict[str, dict[str, list[str]]]] = {}
        self.__lookup_by_vendor_and_product__: dict[str, dict[str, dict[str, list[str]]]] = {}
        self.__lookup_by_product__: dict[str, dict[str, list[str]]] = {}
        self.__load_data__(curated_files, generated_files)

    def __load_data__(self, curated_files: list[str], generated_files: list[str]):
        if not curated_files:
            curated_files = []

        if not generated_files:
            generated_files = []

        for t in self.cpe_types:
            if t not in self.__lookup_by_collection_url_and_package_name__:
                self.__lookup_by_collection_url_and_package_name__[t] = {}
            if t not in self.__lookup_by_vendor_and_product__:
                self.__lookup_by_vendor_and_product__[t] = {}
            if t not in self.__lookup_by_product__:
                self.__lookup_by_product__[t] = {}

        for file in generated_files + curated_files:
            if os.path.exists(file):
                self.logger.debug(f"loading CPE mapping file {file}")
                cpe_type = None
                if file.endswith("/application.json"):
                    cpe_type = "application"
                elif file.endswith("/os.json"):
                    cpe_type = "os"
                elif file.endswith("/hardware.json"):
                    cpe_type = "hardware"
                else:
                    self.logger.warning(f"skipping loading CPE mapping {file} because the type is not recognized")
                    continue

                with open(file) as fp:
                    if "/by_collection_url_and_package_name/" in file:
                        self.__lookup_by_collection_url_and_package_name__[cpe_type] = deep_update(self.__lookup_by_collection_url_and_package_name__[cpe_type], json.load(fp))
                    elif "/by_vendor_and_product/" in file:
                        self.__lookup_by_vendor_and_product__[cpe_type] = deep_update(self.__lookup_by_vendor_and_product__[cpe_type], json.load(fp))
                    elif "/by_product/" in file:
                        self.__lookup_by_product__[cpe_type] = deep_update(self.__lookup_by_product__[cpe_type], json.load(fp))

    def lookup(
        self,
        collection_url: str | None,
        package_name: str | None,
        vendor: str | None,
        product: str | None,
        cpe_types: list[str] | None = None,
    ) -> list[str] | None:
        if not cpe_types:
            cpe_types = self.cpe_types

        collection_url = normalize_collection_url(collection_url)
        package_names = generate_candidates(normalize(package_name))
        vendors = generate_candidates(normalize_vendor(vendor))
        products = generate_candidates(normalize(product))

        if not package_names:
            package_names = products

        if collection_url and package_names:
            for p in package_names:
                cpes = set()
                for t in cpe_types:
                    type_cpes = self.__lookup_by_collection_url_and_package_name__[t].get(collection_url, {}).get(p)
                    if type_cpes:
                        cpes.update(type_cpes)
                if cpes:
                    return cpes

        if vendors and products:
            for v in vendors:
                for p in products:
                    cpes = set()
                    for t in cpe_types:
                        type_cpes = self.__lookup_by_vendor_and_product__[t].get(v, {}).get(p)
                        if type_cpes:
                            cpes.update(type_cpes)
                    if cpes:
                        return cpes

        if products:
            for p in products:
                cpes = set()
                for t in cpe_types:
                    type_cpes = self.__lookup_by_product__[t].get(p)
                    if type_cpes:
                        cpes.update(type_cpes)
                if cpes:
                    return cpes

        return None

curated_files = glob("/Users/weston/github/anchore/nvd-analysis/data/cpe/curated/lookup/**/*.json", recursive=True)
generated_files = glob("/Users/weston/github/anchore/nvd-analysis/data/cpe/generated/lookup/**/*.json", recursive=True)

cpe_lookup = CPEPatternLookup(curated_files, generated_files)
cpe_lookup.cpe_types = ["application"]

def get_existing_nvd_record(cve_id: str) -> dict[str, Any] | None:
    cve_id = cve_id.upper()
    year = cve_id.split("-")[1]
    nvd_record_path = os.path.join(nvd_record_base_path, year, f"{cve_id}.json")
    if not os.path.exists(nvd_record_path):
        logging.debug(f"No NVD record for {cve_id}")
        return None
    
    with open(nvd_record_path, "r") as f:
        logging.debug(f"Loading current NVD record for {cve_id}")
        return json.load(f)

def get_existing_override(cve_id: str) -> dict[str, Any] | None:
    cve_id = cve_id.upper()
    year = cve_id.split("-")[1]
    override_path = os.path.join(nvd_override_base_path, "data", year, f"{cve_id}.json")
    if not os.path.exists(override_path):
        logging.debug(f"No override for {cve_id}")
        return None
    
    with open(override_path, "r") as f:
        logging.debug(f"Loading existing override for {cve_id}")
        return json.load(f)

def persist_override(cve_id: str, nvd_record: dict[str, Any], override_cpe_configurations: list[Any] | None, notes: dict | None):
    cve_id = cve_id.upper()
    logging.info(f"Persisting NVD Override record for {cve_id}")
    nvd_override_record = {
        "cve": {}
    }

    if notes:
        # This is just a way to capture any additional information which might be 
        # useful in evaluating the generated cpe config and should always be removed 
        # prior to upload
        nvd_override_record["_notes"] = notes

    if override_cpe_configurations is not None:
        nvd_override_record["cve"]["configurations"] = override_cpe_configurations
    
    nvd_record_state_capture = {
        "cve": {}
    }

    cpe_config = nvd_record["cve"].get("configurations")

    if cpe_config is not None:
        nvd_record_state_capture["cve"]["configurations"] = cpe_config

    year = cve_id.split("-")[1]

    state_persist_dir = os.path.join(nvd_override_base_path, ".snapshot", year)
    override_persist_dir = os.path.join(nvd_override_base_path, "data", year)
    if not os.path.exists(state_persist_dir):
        os.makedirs(state_persist_dir, exist_ok=True)

    if not os.path.exists(override_persist_dir):
        os.makedirs(override_persist_dir, exist_ok=True)

    with open(os.path.join(state_persist_dir, f"{cve_id}.json"), "w") as fp:
        json.dump(nvd_record_state_capture, fp, indent=2, sort_keys=True)

    with open(os.path.join(override_persist_dir, f"{cve_id}.json"), "w") as fp:
        json.dump(nvd_override_record, fp, indent=2, sort_keys=True)


def process(cve5_record: dict[str, Any]) -> bool:
    if not cve5_record:
        return False
    
    cve_id = cve5_record.get("cveMetadata", {}).get("cveId")

    if not cve_id:
        logging.warning("unable to parse cve id for CVE 5 record")
        return False
    
    if cve_id in ignore_cves:
        return False
    
    nvd_override = get_existing_override(cve_id)
    rejected_date = cve5_record.get("cveMetadata", {}).get("dateRejected")

    if rejected_date:
        logging.debug(f"skipping CVE 5 record for {cve_id} because it has been rejected")
        if nvd_override:
            logging.warning(f"Emptying existing override for {cve_id} because it has been rejected")
            persist_override(cve_id, nvd_record={"cve":{}}, override_cpe_configurations=None)

        return False
    
    assigner = cve5_record.get("cveMetadata", {}).get("assignerShortName")
    if assigner and assigner.lower() in ignore_assigners:
        logging.debug(f"skipping CVE 5 record for {cve_id} because assigner {assigner} is in the ignore list")
        return False

    if only_allowed_assigners:
        if not assigner or assigner.lower() not in allowed_assigners:
            logging.debug(f"skipping CVE 5 record for {cve_id} because assigner {assigner} is not in the automation allowlist")
            return False
    
    logging.debug(f"Processing CVE 5 record for {cve_id}")

    nvd_record = get_existing_nvd_record(cve_id)
    # not currently in scope to create records that don't yet exist at all in NVD, 
    # though could be at a later date if NVD stops working entirely
    if not nvd_record or "cve" not in nvd_record:
        logging.warning(f"No NVD record currently exists for {cve_id}.  Have you pulled in latest")
        return False
    
    if nvd_record["cve"]["vulnStatus"] not in {"Awaiting Analysis", "Received"}:
        return False
    
    nvd_override = get_existing_override(cve_id)

    # TODO: reconcile
    if nvd_override:
        logging.debug(f"There is already an existing override for {cve_id}")
        return False
    
    nvd_configs = nvd_record["cve"].get("configurations")
    if nvd_configs:
        logging.debug(f"CPE configurations already present on NVD record for {cve_id}")
        return False

    cna_node = cve5_record.get("containers", {}).get("cna", {})
    configs = []
    for affected in cna_node.get("affected", []):
        collection_url = affected.get("collectionURL")
        package_name = affected.get("packageName")
        vendor = affected.get("vendor")
        product = affected.get("product")
        cpes = set()
        versioned_cna_cpes = set()

        normalized_vendor = normalize_vendor(vendor)
        normalized_product = normalize(product)

        if normalized_vendor and "oracle" in normalized_vendor:
            if normalized_product and "java" in normalized_product:
                logging.warning(f"{cve_id} for java stuff requires manual review")
                return False

        #if normalize_vendor(vendor) not in ["go standard library", "google.golang.org/protobuf"]:
        #    continue

        for cpe in affected.get("cpes", []):
            if cpe.startswith("cpe:2.3"):
                components = cpe.split(":")
                if len(components) == 13:
                    if components[5] not in {"*", "-"}:
                        versioned_cna_cpes.add(cpe)
                    components[5] = "*"
                    components[6] = "*"
                    logging.debug(f"Adding CPE {cpe!r} provided by the CNA on the CVE record for {cve_id!r}")
                    cpes.add(":".join(components))

        lookup_cpes = cpe_lookup.lookup(collection_url=collection_url, package_name=package_name, vendor=vendor, product=product)
        if lookup_cpes:
            logging.debug(f"Discovered CPES {lookup_cpes!r} via lookups for {cve_id!r}")
            cpes.update(lookup_cpes)

        if not cpes:
            #cpes = cpes_from_vendor_and_product(vendor=vendor, product=product)
            #logging.debug(f"Generated CPES {cpes!r} from vendor={vendor!r}, product={product!r} for {cve_id!r}")
            if not cpes:
                # TODO: create some sort of generator if the values aren't all equivalent to empty
                # for now just bail
                logging.debug(f"No CPEs discovered or generated for affected entry: {affected!r} on {cve_id!r}")
                continue

        # Possible status values are `affected`, `unaffected`, and `unknown`, should be considered `unknown`
        # if not specified
        default_status = affected.get("defaultStatus", "unknown").lower()
        versions = affected.get("versions", [])
        node = {
            "operator": "OR",
            "negate": False,
            "cpeMatch": [],
        }

        for v in versions:
            status = v.get("status", default_status).lower()
            version, less_than, less_than_or_equal, version_type = parse_cpe_5_version_info(v)

            # Correct for RedHat versioning
            if (assigner == "redhat" or assigner == "fedora") and status == "unaffected" and normalize_vendor(vendor) is None and normalize(product) is not None:
                if version and not less_than and not less_than_or_equal:
                    status = "affected"
                    v["status"] = status
                    v["lessThan"] = version
                    v["version"] = None
                    version, less_than, less_than_or_equal, version_type = parse_cpe_5_version_info(v)

            # TODO: Turn versions with `,` into a list of versions
            if version and "," in version:
                logging.debug(f"Skipping version {version} for {cve_id!r}")
                continue

            if version_type == "git":
                logging.debug(f"Skipping git version type for {cve_id!r}")
                continue

            for cpe in cpes:
                if cpe in ignore_cpes:
                    continue

                cpe_vendor = cpe.split(":")[3]
                if cpe_vendor in ignore_vendors:
                    continue
                
                m = {}
                m["criteria"] = cpe
                m["matchCriteriaId"] = str(uuid4()).upper()
                if less_than and less_than != "*":
                    m["versionEndExcluding"] = less_than
                    if version and version != "*":
                        m["versionStartIncluding"] = version
                elif less_than_or_equal and less_than_or_equal != "*":
                    m["versionEndIncluding"] = less_than_or_equal
                    if version and version != "*":
                        m["versionStartIncluding"] = version
                elif version:
                    components = cpe.split(":")
                    components[5] = version
                    m["criteria"] = ":".join(components)
                else:
                    logging.debug(f"no useable version information extracted for affected entry: {affected!r}, version: {v!r} on {cve_id!r}")
                    break

                if status in {"affected", "unknown"}:
                    m["vulnerable"] = True
                elif status in {"unaffected"}:
                    m["vulnerable"] = False

                node["cpeMatch"].append(m)

        if not node["cpeMatch"]:
            continue

        configs.append(
            {
                "nodes": [node],
            },
        )
    if configs:
        logging.info(f"Creating NVD override record for {cve_id!r} with CPE configurations: {configs!r}")
        refs = set()
        for r in cna_node.get("references", []):
            url = r.get("url")
            if url:
                refs.add(url)

        solutions = set()
        for s in cna_node.get("solutions", []):
            solution = s.get("value")
            if solution:
                solutions.add(solution)

        notes = {}

        if refs:
            notes["references"] = list(refs)

        if solutions:
            notes["solutions"] = list(solutions)

        persist_override(cve_id, nvd_record, configs, notes)
        return True
    else:
        logging.warning(f"Unable to automatically determine CPE config for {cve_id} from assigner {assigner}: vendor={vendor}, product={product}, collection_url={collection_url}, package_name={package_name}")

    return False


if __name__ == '__main__':
    created = 0
    logging.basicConfig(level="INFO")

    for cve5_file in cve5_data_files:
        with open(cve5_file) as fp:
            cve5_record = json.load(fp)

        created_override = process(cve5_record)

        if created_override:
            created += 1

        if created >= MAX_BATCH_SIZE:
            logging.warning("stopped processing as maximum created records reached")
            break