import json
import logging
import requests
import re
import sqlite3

from glob import glob

from scripts.normalization import (
    collection_url_from_github_ecosystem,
    normalize_collection_url,
)

url_exists = {}

excluded_cves = {
    "CVE-2024-1139",
    "CVE-2024-35221",  # rubygems.org service
}
excluded_cpes = {
    "cpe:2.3:a:redhat:openshift_container_platform:*:*:*:*:*:*:*:*",
    "cpe:2.3:a:redhat:openshift:*:*:*:*:*:*:*:*",
}
lookup_by_cpe = {}
github_by_cve = {}

excluded_collection_urls = {
    "access.redhat.com",
    "packages.fedoraproject.org",
    "packages.fedoraproject.org",
}

excluded_github_users = {
    "zhuoniba/",
    "wp-plugins/",
    "wp-themes/",
    "advisories/",
    "beatriz-ai-boop/",
    "navaidzansari/",
    "nickguitar/",
    "0day1/",
    "0x72303074/",
    "0xhebi/",
    "0xraw/",
    "0xrayan/",
    "0xuhaw/",
    "v3x0r/",
}

"""
crane export ghcr.io/anchore/grype-db/data/github:latest - | tar -Oxf - github/results/results.db > .tmp/github-result.db
"""


def populate_github_by_cve():
    con = sqlite3.connect(".tmp/github-result.db")
    for row in con.cursor().execute("SELECT record from results;"):
        github_json = json.loads(row[0])["item"]["Advisory"]
        if github_json["withdrawn"] is not None:
            continue

        if "CVE" not in github_json:
            continue

        ghsa = github_json["ghsaId"]
        url = github_json["url"]

        for f in github_json["FixedIn"]:
            ecosystem = f["ecosystem"]
            package_name = f["name"]
            collection_url = collection_url_from_github_ecosystem(f["ecosystem"])

            if not collection_url:
                logging.debug(f"{ghsa} - skipping unknown ecosystem {ecosystem}")
                continue

            for cve in github_json["CVE"]:
                if cve not in github_by_cve:
                    github_by_cve[cve] = {
                        "url": url,
                        "lookup": {},
                    }

                if collection_url not in github_by_cve[cve]["lookup"]:
                    github_by_cve[cve]["lookup"][collection_url] = set()

                github_by_cve[cve]["lookup"][collection_url].add(package_name)


def populate_lookup_by_cpe(filename: str):
    with open(filename, "r") as f:
        for collection_url, packages in json.load(f).items():
            excluded = False
            for u in excluded_collection_urls:
                if collection_url.startswith(u):
                    excluded = True
                    break

            if excluded:
                continue

            for package_name, cpes in packages.items():
                if collection_url.startswith("github.com"):
                    for u in excluded_github_users:
                        if package_name.startswith(u):
                            excluded = True
                            break

                        components = package_name.split("/")
                        if len(components) == 2:
                            m = re.match(r"^CVE-\d{4}-\d+$", components[1], re.IGNORECASE)
                            if m:
                                excluded = True
                                break


                if excluded:
                    continue

                for cpe in cpes:
                    if cpe in excluded_cpes:
                        continue

                    if cpe not in lookup_by_cpe:
                        lookup_by_cpe[cpe] = {}

                    if collection_url.startswith("wordpress.org"):
                        if " " in package_name:
                            continue
                        # TODO: Figure out wordpress plugin issues
                        # package_name = package_name.replace(" ", "-")

                        # url = f"https://{collection_url}/{package_name}"

                        # if url not in url_exists:
                        #     logging.warning(url)
                        #     url_exists[url] = requests.head(url).status_code == 200

                        # if not url_exists[url]:
                        #     continue

                    if collection_url not in lookup_by_cpe[cpe]:
                        lookup_by_cpe[cpe][collection_url] = set()

                    lookup_by_cpe[cpe][collection_url].add(package_name)


# populate_lookup_by_cpe(
#     "data/cpe/generated/lookup/by_collection_url_and_package_name/application.json"
# )
populate_lookup_by_cpe(
    "data/cpe/curated/lookup/by_collection_url_and_package_name/application.json"
)
populate_github_by_cve()

def determine_additional_metadata_from_cpes(
    cve_id: str, collection_url: str, package_name: str, repo: str, cpes: list[str]
):
    collection_url_info = {}

    for cpe in affected["cpes"]:
        metadata = lookup_by_cpe.get(cpe)

        if not metadata:
            continue

        for collection_url, packages in metadata.items():
            if collection_url not in collection_url_info:
                collection_url_info[collection_url] = set()

            collection_url_info[collection_url].update(packages)

    if (
        "github.com" in collection_url_info
        and len(collection_url_info["github.com"]) == 1
    ):
        if not repo:
            p = list(collection_url_info["github.com"])[0]
            repo = f"https://github.com/{p}"
        del collection_url_info["github.com"]

    if len(collection_url_info) > 1:
        logging.warning(
            f"Multiple collectionURL possibilities for {cve_id}.  Please review manually: {collection_url_info}"
        )
        return collection_url, package_name, repo

    if len(collection_url_info) == 1:
        if len(collection_url_info.values()) > 1:
            logging.warning(
                f"Multiple packageName possibilities for {cve_id}.  Please review manually: {list(collection_url_info.values())}"
            )
            return collection_url, package_name, repo

        collection_url = list(collection_url_info.keys())[0]
        package_name = list(list(collection_url_info.values())[0])[0]

        if not repo and collection_url and package_name:
            if collection_url == "wordpress.org/plugins":
                repo = f"https://plugins.svn.wordpress.org/{package_name}"
            elif collection_url == "wordpress.org/themes":
                repo = f"https://themes.svn.wordpress.org/{package_name}"

    if (
        collection_url
        and not repo
        and (
            collection_url.startswith("github.com")
            or collection_url.startswith("gitlab.com")
        )
    ):
        repo = f"https://{collection_url}"
        collection_url = None

    if collection_url == "github.com":
        collection_url = None
        package_name = None

    return collection_url, package_name, repo


for enriched_path in glob(
    "cve-data-enrichment/data/anchore/**/CVE-*.json"
):
    with open(enriched_path) as f:
        enriched = json.load(f)

    cve_id = enriched["additionalMetadata"]["cveId"]

    if cve_id in excluded_cves:
        continue

    affected_records = enriched["adp"]["affected"]

    for affected in affected_records:
        collection_url = normalize_collection_url(affected.get("collectionURL"))
        package_name = affected.get("packageName")
        repo = affected.get("repo")

        if collection_url == "github.com" and package_name and not repo:
            repo = f"https://github.com/{package_name}"

        if not collection_url or collection_url.startswith("github.com"):
            collection_url, package_name, repo = (
                determine_additional_metadata_from_cpes(
                    cve_id, collection_url, package_name, repo, affected["cpes"]
                )
            )

            if len(affected_records) == 1:
                github = github_by_cve.get(cve_id)

                if github and len(github["lookup"]) == 1:
                    collection_url = list(github["lookup"].keys())[0]
                    vals = list(github["lookup"][collection_url])
                    if len(vals) == 1:
                        package_name = vals[0]

        if collection_url:
            if not collection_url.startswith("https://"):
                collection_url = f"https://{collection_url}"

        if collection_url == repo:
            collection_url = None

        if collection_url:
            affected["collectionURL"] = collection_url

        if package_name:
            affected["packageName"] = package_name

        if repo:
            affected["repo"] = repo

    with open(enriched_path, "w") as f:
        json.dump(enriched, f, ensure_ascii=False, sort_keys=True, indent=2)
